# ğŸ§  Neural Assist

A communication interface that allows users to express their needs through neural signals and Bluetooth connectivity. Designed for individuals with motor disabilities to communicate using brain signals.

## ğŸ“‹ Overview

Neural Assist Interface processes real-time brain signals via Bluetooth to control a visual communication board. Users can navigate through communication cards using neural signals and select their needs with audio feedback.

## âœ¨ Features

- ğŸ§  **Neural Signal Control**: Navigate and select using brain signals
- ğŸƒ **Communication Cards**: Food, Help, Outing, Television, Lights, YouTube
- â• **Custom Cards**: Add personalized communication options
- ğŸŒ **Multi-language**: English, Bahasa Melayu, Tamil, Chinese
- ğŸ”Š **Audio Feedback**: Instant sound responses
- ğŸ’¡ **Smart Lighting**: Control connected light systems
- ğŸ“º **YouTube Integration**: Access relaxation videos

## ğŸš€ Quick Start

1. **ğŸ“¦ Install dependencies**
   ```bash
   npm install
   ```

2. **ğŸ”‘ Set up YouTube API** (optional)
   Create `.env.local`:
   ```env
   NEXT_PUBLIC_YT_API_KEY=your_youtube_api_key
   ```

3. **â–¶ï¸ Run the app**
   ```bash
   npm run dev
   ```

4. **ğŸ”— Connect neural device**
   - Click "Connect" button
   - Select "ESP32C6_EEG" from Bluetooth devices
   - Wait for connection confirmation

## ğŸ® How to Use

### ğŸ§  Neural Navigation
- **ğŸ‘ï¸ S Mode**: Navigate through cards by blinking
- **ğŸ¯ A Mode**: focus to select the highlighted card

### â• Adding Custom Cards
1. Click "Add Communication Card"
2. Enter card name and choose icon
3. Card appears in the interface

### ğŸŒ Language Selection
Click the language dropdown in the header to change interface language.

## ğŸ“‹ Requirements

- ğŸ“± Bluetooth-enabled device
- ğŸ§  Neural signal device (ESP32C6_EEG)
- ğŸŒ Modern web browser with Web Bluetooth support

## ğŸ› ï¸ Technology

Built with Next.js, React, TypeScript, and Tailwind CSS. Uses Web Bluetooth API for neural device communication.